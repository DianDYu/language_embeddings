# Language Embeddings for Typology and Cross-lingual Transfer Learning

Trained language embeddings and scripts for the paper:

[**Language Embeddings for Typology and Cross-lingual Transfer Learning**](). [**Dian Yu**](), [**Taiqi He**]() and [**Kenji Sagae**](). ACL 2021


## Abstract
Cross-lingual language tasks typically requirea substantial amount of annotated data or par-allel  translation  data.We  explore  whetherlanguage representations that capture relation-ships  among  languages  can  be  learned  andsubsequently leveraged in cross-lingual taskswithout  the  use  of  parallel  data.   We  gener-ate dense embeddings for 29 languages usinga denoising autoencoder, and evaluate the em-beddings using the World Atlas of LanguageStructures (WALS) and two extrinsic tasks ina zero-shot setting:  cross-lingual dependencyparsing and cross-lingual natural language in-ference.


## Bibtex:
<pre>
@inproceedings{yu-etal-2021-language,
  title={Language Embeddings for Typology and Cross-lingual Transfer Learning},
  author={Yu, Dian and He, Taiqi and Sagae, Kenji},
  booktitle={Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics},
  pages={},
  year={2021}
}
</pre>
